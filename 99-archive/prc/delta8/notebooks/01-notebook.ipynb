{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration\n",
    "\n",
    "- This notebook demonstrates key components of our Delta 8 analysis project.\n",
    "- It shows how we preprocess tweets, extract keywords, analyze sentiment, and generate themes.\n",
    "- These techniques can be applied to larger datasets for more comprehensive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's import the necessary libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some sample tweets for our demonstration\n",
    "sample_tweets = [\n",
    "    \"Delta 8 THC offers a milder high compared to traditional marijuana.\",\n",
    "    \"Just tried Delta 8 gummies and they helped with my anxiety!\",\n",
    "    \"Is Delta 8 legal? Need to check the regulations in my state.\",\n",
    "    \"Delta 8 products are becoming popular, but we need more research on long-term effects.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Keep only nouns, verbs, and adjectives\n",
    "    tokens = [word for word, pos in pos_tag(tokens) if pos.startswith(('N', 'V', 'J'))]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's preprocess our sample tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tweets = [preprocess_text(tweet) for tweet in sample_tweets]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(texts, top_n=5):\n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        all_words.extend(text)\n",
    "    return Counter(all_words).most_common(top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract top keywords from our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top keywords:\n",
      "delta: 3\n",
      "thc: 1\n",
      "offers: 1\n",
      "milder: 1\n",
      "high: 1\n"
     ]
    }
   ],
   "source": [
    "top_keywords = extract_keywords(preprocessed_tweets)\n",
    "\n",
    "print(\"\\nTop keywords:\")\n",
    "for keyword, count in top_keywords:\n",
    "    print(f\"{keyword}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    return sia.polarity_scores(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweet: Delta 8 THC offers a milder high compared to traditional marijuana.\n",
      "Sentiment: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "Tweet: Just tried Delta 8 gummies and they helped with my anxiety!\n",
      "Sentiment: {'neg': 0.181, 'neu': 0.819, 'pos': 0.0, 'compound': -0.2481}\n",
      "\n",
      "Tweet: Is Delta 8 legal? Need to check the regulations in my state.\n",
      "Sentiment: {'neg': 0.0, 'neu': 0.87, 'pos': 0.13, 'compound': 0.128}\n",
      "\n",
      "Tweet: Delta 8 products are becoming popular, but we need more research on long-term effects.\n",
      "Sentiment: {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'compound': 0.2263}\n"
     ]
    }
   ],
   "source": [
    "# Analyze sentiment for each sample tweet\n",
    "for tweet in sample_tweets:\n",
    "    sentiment = analyze_sentiment(tweet)\n",
    "    print(f\"\\nTweet: {tweet}\")\n",
    "    print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Theme Generation (Simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_themes(keywords):\n",
    "    themes = {\n",
    "        \"Product\": [\"delta\", \"thc\", \"gummies\"],\n",
    "        \"Effects\": [\"high\", \"anxiety\"],\n",
    "        \"Legality\": [\"legal\", \"regulations\"],\n",
    "        \"Research\": [\"effects\", \"research\"]\n",
    "    }\n",
    "    \n",
    "    keyword_themes = {}\n",
    "    for keyword, _ in keywords:\n",
    "        for theme, theme_keywords in themes.items():\n",
    "            if keyword in theme_keywords:\n",
    "                if theme not in keyword_themes:\n",
    "                    keyword_themes[theme] = []\n",
    "                keyword_themes[theme].append(keyword)\n",
    "    \n",
    "    return keyword_themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate themes from our top keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Themes:\n",
      "Product: delta, thc\n",
      "Effects: high\n"
     ]
    }
   ],
   "source": [
    "themes = generate_themes(top_keywords)\n",
    "\n",
    "print(\"\\nGenerated Themes:\")\n",
    "for theme, keywords in themes.items():\n",
    "    print(f\"{theme}: {', '.join(keywords)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundtrip example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Analysis of a Tweet:\n",
      "Original Tweet: Delta 8 THC is gaining popularity, but we need more research on its long-term effects and legal status.\n",
      "Preprocessed: ['delta', 'thc', 'gaining', 'popularity', 'need', 'research', 'long-term', 'effects', 'legal', 'status']\n",
      "Sentiment: {'neg': 0.0, 'neu': 0.711, 'pos': 0.289, 'compound': 0.5719}\n"
     ]
    }
   ],
   "source": [
    "def analyze_tweet(tweet):\n",
    "    preprocessed = preprocess_text(tweet)\n",
    "    sentiment = analyze_sentiment(tweet)\n",
    "    return preprocessed, sentiment\n",
    "\n",
    "print(\"\\nComplete Analysis of a Tweet:\")\n",
    "sample_tweet = \"Delta 8 THC is gaining popularity, but we need more research on its long-term effects and legal status.\"\n",
    "preprocessed, sentiment = analyze_tweet(sample_tweet)\n",
    "\n",
    "print(f\"Original Tweet: {sample_tweet}\")\n",
    "print(f\"Preprocessed: {preprocessed}\")\n",
    "print(f\"Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Analysis of a Tweet:\n",
      "Original Tweet: Delta 8 THC is harsh but it's the only thing I can buy.\n",
      "Preprocessed: ['delta', 'thc', 'harsh', 'thing', 'buy']\n",
      "Sentiment: {'neg': 0.163, 'neu': 0.837, 'pos': 0.0, 'compound': -0.2382}\n"
     ]
    }
   ],
   "source": [
    "def analyze_tweet(tweet):\n",
    "    preprocessed = preprocess_text(tweet)\n",
    "    sentiment = analyze_sentiment(tweet)\n",
    "    return preprocessed, sentiment\n",
    "\n",
    "print(\"\\nComplete Analysis of a Tweet:\")\n",
    "sample_tweet = \"Delta 8 THC is harsh but it's the only thing I can buy.\"\n",
    "preprocessed, sentiment = analyze_tweet(sample_tweet)\n",
    "\n",
    "print(f\"Original Tweet: {sample_tweet}\")\n",
    "print(f\"Preprocessed: {preprocessed}\")\n",
    "print(f\"Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Sentiment Scores\n",
    "\n",
    "The sentiment scores provided are based on the VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool, which is specifically attuned to sentiments expressed in social media. VADER uses a combination of a sentiment lexicon and rule-based analysis to produce four scores: 'neg', 'neu', 'pos', and 'compound'. The 'neg', 'neu', and 'pos' scores represent the proportion of the text that falls into negative, neutral, and positive categories respectively, and they sum to 1. These scores provide a breakdown of the sentiment composition of the text.\n",
    "\n",
    "The 'compound' score is a unified sentiment measure, computed by summing the valence scores of each word in the lexicon, adjusted according to rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This score is the most useful for determining overall sentiment. Generally, a compound score ≤ -0.05 is considered negative, a score ≥ 0.05 is considered positive, and anything in between is considered neutral. However, these thresholds can be adjusted based on your specific needs and the nature of your data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
