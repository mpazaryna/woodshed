{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn LangGraph: The Weather Map Example\n",
    "\n",
    "This code is a walk through from [Learn LangGraph - The Easy Way](https://youtu.be/R8KB-Zcynxc?si=M5RDpfIdMA-cvisY) and the code found at [code](https://github.com/menloparklab/LangGraphJourney/blob/main/LangGraphLearning.ipynb)\n",
    "\n",
    "This tutorial offers a step-by-step guide to building agent applications using LangGraph, a library offered by LangChain. Starting with an overview of LangGraph and its benefits, the tutorial first explores how to make a simple graph and create nodes. It goes on to explain how to create functions and run within nodes. It also covers importing LangChain tools, binding them to the model, how to parse information from nodes, and setting up a state graph. Finally, the tutorial covers adding a conditional edge to the graph and demonstrates running the graph using user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = OpenWeatherMapAPIWrapper()\n",
    "model = ChatOpenAI(temperature=0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes as function calls, that returns a value and sends it to the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_agent(input_1):\n",
    "    complete_query = \"Your task is to provide only the city name based on the user query. \\\n",
    "        Nothing more, just the city name mentioned. Following is the user query: \" + input_1\n",
    "    response = model.invoke(complete_query)\n",
    "    return response.content\n",
    "\n",
    "def function_2(input_2):\n",
    "    return \"Agent Says: \" + input_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph\n",
    "\n",
    "# Define a Langchain graph\n",
    "workflow = Graph()\n",
    "\n",
    "#calling node 1 as agent\n",
    "workflow.add_node(\"agent\", function_agent)\n",
    "workflow.add_node(\"node_2\", function_2)\n",
    "\n",
    "workflow.add_edge('agent', 'node_2')\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"node_2\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Asbury Park, NJ, USA, the current weather is as follows:\n",
      "Detailed status: few clouds\n",
      "Wind speed: 4.12 m/s, direction: 180°\n",
      "Humidity: 35%\n",
      "Temperature: \n",
      "  - Current: 25.12°C\n",
      "  - High: 26.57°C\n",
      "  - Low: 23.53°C\n",
      "  - Feels like: 24.6°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 20%\n"
     ]
    }
   ],
   "source": [
    "weather_data = weather.run(\"Asbury Park, NJ, USA\")\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_community.tools.openweathermap import OpenWeatherMapQueryRun\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "tools = [OpenWeatherMapQueryRun()]\n",
    "\n",
    "model = ChatOpenAI(temperature=0, streaming=True)\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the task is to parse out the city name from the user query\n",
    "def function_1(state):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "def function_2(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] # this has the query we need to send to the tool provided by the agent\n",
    "\n",
    "    parsed_tool_input = json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"])\n",
    "\n",
    "    # We construct an ToolInvocation from the function_call and pass in the tool name and the expected str input for OpenWeatherMap tool\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=parsed_tool_input['__arg1'],\n",
    "    )\n",
    "    \n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}\n",
    "\n",
    "def function_3(state):\n",
    "    messages = state['messages']\n",
    "    user_input = messages[0]\n",
    "    available_info = messages[-1]\n",
    "    agent2_query = \"Your task is to provide info concisely based on the user query and the available information from the internet. \\\n",
    "                        Following is the user query: \" + user_input + \" Available information: \" + available_info\n",
    "    response = model.invoke(agent2_query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_to_go(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if \"function_call\" in last_message.additional_kwargs:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import StateGraph and pass AgentState to it\n",
    "from langgraph.graph import StateGraph, END\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"tool\", function_2)\n",
    "\n",
    "# The conditional edge requires the following info below.\n",
    "# First, we define the start node. We use `agent`.\n",
    "# This means these are the edges taken after the `agent` node is called.\n",
    "# Next, we pass in the function that will determine which node is called next, in our case where_to_go().\n",
    "\n",
    "\n",
    "# Based on the return from where_to_go, we define the next nodes to be called. If the return is \"continue\" then we call the tool node.\n",
    "# Otherwise we finish. END is a special node marking that the graph should finish.\n",
    "workflow.add_conditional_edges(\"agent\", where_to_go,{\"continue\": \"tool\", \"end\": END})\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that if `tool` is called, then it has to call the 'agent' next. \n",
    "workflow.add_edge('tool', 'agent')\n",
    "\n",
    "# Basically, agent node has the option to call a tool node based on a condition, \n",
    "# whereas tool node must call the agent in all cases based on this setup.\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the temperature in las vegas'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"Las Vegas\"}', 'name': 'open_weather_map'}}, response_metadata={'finish_reason': 'function_call'}, id='run-96abedb8-53aa-4160-9d15-189474a8b1ca-0'),\n",
       "  FunctionMessage(content='In Las Vegas, the current weather is as follows:\\nDetailed status: clear sky\\nWind speed: 4.92 m/s, direction: 60°\\nHumidity: 20%\\nTemperature: \\n  - Current: 17.3°C\\n  - High: 19.31°C\\n  - Low: 15.93°C\\n  - Feels like: 15.61°C\\nRain: {}\\nHeat index: None\\nCloud cover: 0%', name='open_weather_map'),\n",
       "  AIMessage(content='The current temperature in Las Vegas is 17.3°C. It is a clear sky with a humidity of 20%. The wind speed is 4.92 m/s.', response_metadata={'finish_reason': 'stop'}, id='run-013639b2-2f6e-48fa-9f40-a09b355ceb16-0')]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"what is the temperature in las vegas\")]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How are you?'),\n",
       "  AIMessage(content=\"I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\", response_metadata={'finish_reason': 'stop'}, id='run-45e951e1-35b1-4796-a166-1da8164ce718-0')]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"How are you?\")]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation Use Only\n",
    "\n",
    "Run the cell if you want to review the contents in each of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"Las Vegas\"}', 'name': 'open_weather_map'}}, response_metadata={'finish_reason': 'function_call'}, id='run-db9d1535-a626-4c5c-9fce-9b14786329ea-0')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tool':\n",
      "---\n",
      "{'messages': [FunctionMessage(content='In Las Vegas, the current weather is as follows:\\nDetailed status: clear sky\\nWind speed: 4.92 m/s, direction: 60°\\nHumidity: 19%\\nTemperature: \\n  - Current: 17.26°C\\n  - High: 18.57°C\\n  - Low: 16.2°C\\n  - Feels like: 15.54°C\\nRain: {}\\nHeat index: None\\nCloud cover: 0%', name='open_weather_map')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='The current temperature in Las Vegas is 17.26°C. It feels like 15.54°C with clear skies and a humidity of 19%.', response_metadata={'finish_reason': 'stop'}, id='run-74ca072c-11b7-4a94-87d6-00fcf3a165e1-0')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "inputs = {\"messages\": [HumanMessage(content=\"what is the temperature in las vegas\")]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content=\"I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\", response_metadata={'finish_reason': 'stop'}, id='run-13bf4c50-6360-4fd9-b34a-1312fe1129c3-0')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "inputs = {\"messages\": [HumanMessage(content=\"How are you?\")]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
