{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Low-latency Large Language Models (LLMs) are crucial in various applications where real-time or near-real-time processing is essential. Here are some reasons why low-latency LLMs are important:\\n\\n1. **Conversational AI**: In conversational AI, low-latency LLMs enable more natural and human-like interactions. Fast response times are critical in chatbots, virtual assistants, and voice assistants, where users expect immediate responses to their queries.\\n2. **Real-time Language Translation**: Low-latency LLMs facilitate real-time language translation, enabling instant communication across language barriers. This is particularly important in applications like live subtitles, simultaneous interpretation, and multilingual customer support.\\n3. **Sentiment Analysis and Feedback**: In customer service and feedback systems, low-latency LLMs can quickly analyze customer sentiment, enabling prompt responses to customer concerns and improving overall customer experience.\\n4. **Content Generation and Summarization**: Low-latency LLMs can rapidly generate content, such as news summaries, product descriptions, or social media posts, allowing for timely and relevant information dissemination.\\n5. **Gaming and Interactive Systems**: In gaming and interactive systems, low-latency LLMs can enhance the user experience by providing rapid responses to user input, creating a more immersive and engaging experience.\\n6. **Healthcare and Emergency Services**: In healthcare and emergency services, low-latency LLMs can facilitate rapid analysis of medical data, enabling timely diagnosis and treatment. They can also help emergency responders quickly understand and respond to emergency situations.\\n7. **Autonomous Systems**: In autonomous systems, such as self-driving cars or drones, low-latency LLMs can rapidly process and respond to sensory data, ensuring timely and accurate decision-making.\\n8. **Edge AI and IoT**: Low-latency LLMs can be deployed at the edge, enabling real-time processing and analysis of data from IoT devices, such as smart home devices, industrial sensors, or surveillance cameras.\\n9. **Cybersecurity**: In cybersecurity, low-latency LLMs can quickly analyze network traffic and system logs, enabling rapid detection and response to security threats.\\n10. **Competitive Advantage**: In many industries, low-latency LLMs can provide a competitive advantage by enabling faster decision-making, improved customer experiences, and increased operational efficiency.\\n\\nIn summary, low-latency LLMs are essential in applications where timely processing and response are critical. They can improve user experiences, enable real-time decision-making, and provide a competitive edge in various industries.', response_metadata={'token_usage': {'completion_time': 1.4376179439999999, 'completion_tokens': 511, 'prompt_time': 0.00935495, 'prompt_tokens': 32, 'queue_time': None, 'total_time': 1.446972894, 'total_tokens': 543}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-196b2671-72f6-43f3-9ce4-ea9ec832e09b-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"You are a helpful assistant.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke({\"text\": \"Explain the importance of low latency LLMs.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
