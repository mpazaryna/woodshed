{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install a Pinecone client\n",
    "\n",
    "Pinecone exposes a simple REST API for interacting with your vector database. You can use the API directly, or you can use one of the official Pinecone clients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize your connection\n",
    "\n",
    "Using your API key and environment, initialize your client connection to Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m load_dotenv(find_dotenv())\n\u001b[1;32m      7\u001b[0m API_KEY\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPINECONE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masia-southeast1-gcp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/woodshed/lib/python3.11/site-packages/pinecone/deprecation_warnings.py:38\u001b[0m, in \u001b[0;36minit\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m    import os\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m        )\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mPlease create an instance of the Pinecone class instead.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pinecone\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import tqdm\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "API_KEY=os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "pinecone.init(api_key=API_KEY, environment=\"asia-southeast1-gcp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index\n",
    "\n",
    "In Pinecone, you store vector embeddings in indexes. In each index, the vectors share the same dimensionality and distance metric for measuring similarity.\n",
    "\n",
    "Create an index named \"quickstart\" that performs nearest-neighbor search using the Euclidean distance metric for 8-dimensional vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexDescription(name='quickstart', metric='euclidean', replicas=1, dimension=8.0, shards=1, pods=1, pod_type='p1.x1', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.create_index(\"quickstart\", dimension=8, metric=\"euclidean\")\n",
    "pinecone.describe_index(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(\"quickstart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert vectors\n",
    "\n",
    "Now that you've created your index, insert sample vectors into 2 distinct namespaces.\n",
    "\n",
    "Namespaces let you partition vectors within a single index. Although optional, they are a best practice for speeding up queries, which can be filtered by namespace, and for complying with multi-tenancy requirements.\n",
    "\n",
    "Create a client instance that targets the \"quickstart\" index:\n",
    "Use the upsert operation to write 8 8-dimensional vectors into 2 distinct namespaces\n",
    "\n",
    "When upserting larger amounts of data, upsert data in batches of 100 vectors or fewer over multiple upsert requests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upsert(\n",
    "  vectors=[\n",
    "    {\"id\": \"vec1\", \"values\": [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]},\n",
    "    {\"id\": \"vec2\", \"values\": [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]},\n",
    "    {\"id\": \"vec3\", \"values\": [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]},\n",
    "    {\"id\": \"vec4\", \"values\": [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4]}\n",
    "  ],\n",
    "  namespace=\"ns1\"\n",
    ")\n",
    "\n",
    "index.upsert(\n",
    "  vectors=[\n",
    "    {\"id\": \"vec5\", \"values\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]},\n",
    "    {\"id\": \"vec6\", \"values\": [0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6]},\n",
    "    {\"id\": \"vec7\", \"values\": [0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7]},\n",
    "    {\"id\": \"vec8\", \"values\": [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]}\n",
    "  ],\n",
    "  namespace=\"ns2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the index\n",
    "\n",
    "Pinecone is eventually consistent, so there can be a delay before your vectors are visible to queries. Use the describe_index_stats operation to check if the current vector count matches the number of vectors you inserted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 8,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'ns1': {'vector_count': 4}, 'ns2': {'vector_count': 4}},\n",
       " 'total_vector_count': 8}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a similarity search\n",
    "\n",
    "Query each namespace in your index for the 3 vectors that are most similar to an example 8-dimensional vector, using the Euclidean distance metric you specified for the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'vec7',\n",
       "              'score': 0.0,\n",
       "              'values': [0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7]},\n",
       "             {'id': 'vec8',\n",
       "              'score': 0.0799999237,\n",
       "              'values': [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]},\n",
       "             {'id': 'vec6',\n",
       "              'score': 0.0799999237,\n",
       "              'values': [0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6]}],\n",
       " 'namespace': 'ns2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\n",
    "  namespace=\"ns1\",\n",
    "  vector=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
    "  top_k=3,\n",
    "  include_values=True\n",
    ")\n",
    "\n",
    "index.query(\n",
    "  namespace=\"ns2\",\n",
    "  vector=[0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7],\n",
    "  top_k=3,\n",
    "  include_values=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "The Starter plan allows only a single index, so once you're done with the \"quickstart\" index, use the delete_index operation to delete it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.delete_index(\"quickstart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmentation in LangChain\n",
    "\n",
    "LLMs have a data freshness problem. The most powerful LLMs in the world, like GPT-4, have no idea about recent world events.\n",
    "\n",
    "The world of LLMs is frozen in time. Their world exists as a static snapshot of the world as it was within their training data.\n",
    "\n",
    "A solution to this problem is retrieval augmentation. The idea behind this is that we retrieve relevant information from an external knowledge base and give that information to our LLM. In this notebook we will learn how to do that.\n",
    "\n",
    "To begin, we must install the prerequisite libraries that we will be using in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install -qU langchain==0.0.162 openai tiktoken \"pinecone-client[grpc]\" datasets apache_beam mwparserfromhell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikipedia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20220301.simple\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[:10000]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m data\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"wikipedia\", \"20220301.simple\", split='train[:10000]')\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
